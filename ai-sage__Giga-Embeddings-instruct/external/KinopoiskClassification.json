{"dataset_revision": "5911f26666ac11af46cb9c6849d0dc80a378af24", "evaluation_time": 119.80069732666016, "kg_co2_emissions": null, "mteb_version": "1.15.3", "scores": {"test": [{"accuracy": 0.7488666666666667, "f1": 0.726314130184491, "f1_weighted": 0.7263141301844909, "hf_subset": "default", "languages": ["rus-Cyrl"], "main_score": 0.7488666666666667, "scores_per_experiment": [{"accuracy": 0.7593333333333333, "f1": 0.742034446305042, "f1_weighted": 0.7420344463050419}, {"accuracy": 0.738, "f1": 0.7056153262604875, "f1_weighted": 0.7056153262604876}, {"accuracy": 0.7586666666666667, "f1": 0.7355771482191243, "f1_weighted": 0.7355771482191242}, {"accuracy": 0.7386666666666667, "f1": 0.7092601759743893, "f1_weighted": 0.7092601759743893}, {"accuracy": 0.7293333333333334, "f1": 0.7110132979731344, "f1_weighted": 0.7110132979731343}, {"accuracy": 0.7593333333333333, "f1": 0.7370940839026124, "f1_weighted": 0.7370940839026123}, {"accuracy": 0.736, "f1": 0.7119796910322566, "f1_weighted": 0.7119796910322566}, {"accuracy": 0.7573333333333333, "f1": 0.7373386553330862, "f1_weighted": 0.7373386553330862}, {"accuracy": 0.7566666666666667, "f1": 0.7382620389484612, "f1_weighted": 0.7382620389484612}, {"accuracy": 0.7553333333333333, "f1": 0.7349664378963153, "f1_weighted": 0.7349664378963154}]}]}, "task_name": "KinopoiskClassification"}